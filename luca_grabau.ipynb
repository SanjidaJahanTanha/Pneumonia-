{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOazXlrBN94rfrgwQrCkwm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanjidaJahanTanha/Pneumonia-/blob/main/luca_grabau.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This repository provides a comprehensive solution to detect and localize pneumonia using chest X-ray images from the RSNA Pneumonia Detection Challenge dataset. The code uses a modified ResNet-50 architecture to perform the dual task of classification and bounding box regression."
      ],
      "metadata": {
        "id": "DEbW27XvpT68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -q pydicom\n",
        "import pandas as pd\n",
        "import pydicom\n",
        "import os\n",
        "import math\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torchvision import models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches"
      ],
      "metadata": {
        "id": "9itQZTVapxim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to measure overlap between predicted and target bounding boxes by intersection over union (IOU)\n",
        "def bb_intersection_over_union(boxA, boxB):\n",
        "    # determine the (x, y)-coordinates of the intersection rectangle\n",
        "    xA = max(boxA[0], boxB[0])\n",
        "    yA = max(boxA[1], boxB[1])\n",
        "    xB = min(boxA[2], boxB[2])\n",
        "    yB = min(boxA[3], boxB[3])\n",
        "\n",
        "    # compute the area of intersection rectangle\n",
        "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
        "\n",
        "    # compute the area of both the prediction and ground-truth rectangles\n",
        "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
        "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
        "\n",
        "    # compute the intersection over union by taking the intersection\n",
        "    # area and dividing it by the sum of prediction + ground-truth\n",
        "    # areas - the intersection area\n",
        "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
        "\n",
        "    # return the intersection over union value\n",
        "    return iou"
      ],
      "metadata": {
        "id": "0FdkGSmop13W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdA-PaiArEtF",
        "outputId": "3e3b5b50-41d8-485f-86cf-292ba875831b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to dataset\n",
        "root_dir = '/content/drive/MyDrive/rsna_pneumonia/'\n",
        "img_dir = os.path.join(root_dir, 'stage_2_train_images')\n",
        "test_img_dir = os.path.join(root_dir, 'stage_2_test_images')\n",
        "label_file = os.path.join(root_dir, 'stage_2_train_labels.csv')"
      ],
      "metadata": {
        "id": "3n0hSlmhp4AP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the CSV files\n",
        "train_labels = pd.read_csv('/content/drive/MyDrive/rsna_pneumonia/stage_2_train_labels.csv')\n",
        "detailed_class_info = pd.read_csv('/content/drive/MyDrive/rsna_pneumonia/stage_2_detailed_class_info.csv')\n",
        "print(\"Loaded CSV Files\")\n",
        "print(train_labels.head())\n",
        "print(detailed_class_info.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgAq5Oswp68X",
        "outputId": "9aebcdf8-b9de-466b-8425-a1ef2ac33d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded CSV Files\n",
            "                              patientId      x      y  width  height  Target\n",
            "0  0004cfab-14fd-4e49-80ba-63a80b6bddd6    NaN    NaN    NaN     NaN       0\n",
            "1  00313ee0-9eaa-42f4-b0ab-c148ed3241cd    NaN    NaN    NaN     NaN       0\n",
            "2  00322d4d-1c29-4943-afc9-b6754be640eb    NaN    NaN    NaN     NaN       0\n",
            "3  003d8fa0-6bf1-40ed-b54c-ac657f8495c5    NaN    NaN    NaN     NaN       0\n",
            "4  00436515-870c-4b36-a041-de91049b9ab4  264.0  152.0  213.0   379.0       1\n",
            "                              patientId                         class\n",
            "0  0004cfab-14fd-4e49-80ba-63a80b6bddd6  No Lung Opacity / Not Normal\n",
            "1  00313ee0-9eaa-42f4-b0ab-c148ed3241cd  No Lung Opacity / Not Normal\n",
            "2  00322d4d-1c29-4943-afc9-b6754be640eb  No Lung Opacity / Not Normal\n",
            "3  003d8fa0-6bf1-40ed-b54c-ac657f8495c5                        Normal\n",
            "4  00436515-870c-4b36-a041-de91049b9ab4                  Lung Opacity\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Merge the dataframes on 'patientId'\n",
        "# combined_labels = pd.merge(train_labels, detailed_class_info, on='patientId', how='left')\n",
        "# # Remove duplicates based on 'patientId'\n",
        "# combined_labels = combined_labels.drop_duplicates(['patientId'])\n",
        "# # for setting limit: combined_labels = combined_labels.sample(n=5)\n",
        "# print(\"\\nMerged CSV Files\")\n",
        "# print(combined_labels.head())"
      ],
      "metadata": {
        "id": "9PHvTqSfp8wO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Path to dataset\n",
        "root_dir = '/content/drive/MyDrive/rsna_pneumonia/'\n",
        "img_dir = os.path.join(root_dir, 'stage_2_train_images')\n",
        "label_file = os.path.join(root_dir, 'stage_2_train_labels.csv')\n",
        "detailed_class_info_file = os.path.join(root_dir, 'stage_2_detailed_class_info.csv')\n",
        "\n",
        "# Load the labels and detailed class info\n",
        "train_labels = pd.read_csv(label_file)\n",
        "detailed_class_info = pd.read_csv(detailed_class_info_file)\n",
        "\n",
        "# List the files in the directory to get patientIds\n",
        "file_list = os.listdir(img_dir)\n",
        "patient_ids_12k = [os.path.splitext(file)[0] for file in file_list]\n",
        "\n",
        "# Convert to a unique list if not already unique\n",
        "patient_ids_12k = list(set(patient_ids_12k))\n",
        "\n",
        "# Filter the train_labels DataFrame to include only the patientIds in the 12k dataset\n",
        "filtered_train_labels = train_labels[train_labels['patientId'].isin(patient_ids_12k)]\n",
        "\n",
        "# Merge the dataframes on 'patientId'\n",
        "combined_labels = pd.merge(filtered_train_labels, detailed_class_info, on='patientId', how='left')\n",
        "\n",
        "# Remove duplicates based on 'patientId'\n",
        "combined_labels = combined_labels.drop_duplicates(['patientId'])\n",
        "\n",
        "# for setting limit: combined_labels = combined_labels.sample(n=5)\n",
        "print(\"\\nMerged CSV Files\")\n",
        "print(combined_labels.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnZ5lUgA53uh",
        "outputId": "7f9ab61a-fd4a-462c-bce7-15fc111b186a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Merged CSV Files\n",
            "                              patientId      x      y  width  height  Target  \\\n",
            "0  0004cfab-14fd-4e49-80ba-63a80b6bddd6    NaN    NaN    NaN     NaN       0   \n",
            "1  00313ee0-9eaa-42f4-b0ab-c148ed3241cd    NaN    NaN    NaN     NaN       0   \n",
            "2  00322d4d-1c29-4943-afc9-b6754be640eb    NaN    NaN    NaN     NaN       0   \n",
            "3  003d8fa0-6bf1-40ed-b54c-ac657f8495c5    NaN    NaN    NaN     NaN       0   \n",
            "4  00436515-870c-4b36-a041-de91049b9ab4  264.0  152.0  213.0   379.0       1   \n",
            "\n",
            "                          class  \n",
            "0  No Lung Opacity / Not Normal  \n",
            "1  No Lung Opacity / Not Normal  \n",
            "2  No Lung Opacity / Not Normal  \n",
            "3                        Normal  \n",
            "4                  Lung Opacity  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i3qpd1DD4a0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to transform input images for preprocessing\n",
        "def transform_image(file_path):\n",
        "    ds = pydicom.dcmread(file_path)\n",
        "    img = Image.fromarray(ds.pixel_array)  # Convert to PIL image\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.Grayscale(num_output_channels=3),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    input_tensor = preprocess(img)\n",
        "    return input_tensor"
      ],
      "metadata": {
        "id": "B8vmlCnrp_Hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess all training_images in a directory\n",
        "print(\"\\nConverting to PIL and transforming to tensor\")\n",
        "def preprocess_images(img_dir):\n",
        "    patient_ids = [filename[:-4] for filename in os.listdir(img_dir) if filename.endswith('.dcm')]\n",
        "    training_images = {}\n",
        "    for filename in tqdm(patient_ids, desc=\"Processing images\", unit=\"image\"):\n",
        "        file_path = os.path.join(img_dir, filename + '.dcm')\n",
        "        if os.path.exists(file_path):\n",
        "            image_tensor = transform_image(file_path)\n",
        "            training_images[filename + '.dcm'] = image_tensor\n",
        "    return training_images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpFJG6ErqBax",
        "outputId": "468eab17-f9fb-416b-9e79-b64dab4ae727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Converting to PIL and transforming to tensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom mapping for class column\n",
        "class_mapping = {'No Lung Opacity / Not Normal': 0, 'Normal': 1, 'Lung Opacity': 2}\n",
        "combined_labels['class'] = combined_labels['class'].map(class_mapping)\n",
        "\n",
        "\n",
        "combined_labels.set_index('patientId', inplace=True) # Replacing indices with patientIds\n",
        "labels = combined_labels.to_dict('index') # Converting the dataframe to a dictionary\n",
        "print(\"\\nNumber of unique patient IDs (entries in labels): \", len(labels))\n",
        "\n",
        "\n",
        "# Preprocess training images\n",
        "train_img_dir = os.path.join(root_dir, 'stage_2_train_images')\n",
        "training_images = preprocess_images(train_img_dir)\n",
        "\n",
        "# Generate a list of patient IDs (get rid of .dcm in the filename)\n",
        "preprocessed_ids = [img_file[:-4] for img_file in training_images.keys()]\n",
        "\n",
        "# Preprocess test images\n",
        "max_test_images = None  # Add the limit here\n",
        "test_img_dir = os.path.join(root_dir, 'stage_2_test_images')\n",
        "test_images = preprocess_images(test_img_dir)\n",
        "\n",
        "print(f\"Preprocessed {len(training_images)} Train Images\")\n",
        "print(f\"Preprocessed {len(test_images)} Test Images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G16RpS_qDOF",
        "outputId": "9a802931-3176-46ff-d62d-6b2d2e47a943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of unique patient IDs (entries in labels):  12272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing images: 100%|██████████| 12309/12309 [09:32<00:00, 21.49image/s]\n",
            "Processing images: 100%|██████████| 3011/3011 [02:14<00:00, 22.40image/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed 12309 Train Images\n",
            "Preprocessed 3011 Test Images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#handling NaN values for Target = 0 (no bounding box)\n",
        "def get_label(patientId):\n",
        "    label_info = labels[patientId]\n",
        "    if math.isnan(label_info['x']):\n",
        "        label_info['x'] = 0\n",
        "    if math.isnan(label_info['y']):\n",
        "        label_info['y'] = 0\n",
        "    if math.isnan(label_info['width']):\n",
        "        label_info['width'] = 0\n",
        "    if math.isnan(label_info['height']):\n",
        "        label_info['height'] = 0\n",
        "    return label_info"
      ],
      "metadata": {
        "id": "u5KdG2IHqGQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine training_images and labels into a list of tuples\n",
        "# Skip training_images without labels\n",
        "data = [(training_images[img_file], get_label(img_file[:-4])) for img_file in training_images if img_file[:-4] in labels]\n",
        "print(f\"\\nCombined labels and training images into {len(data)} data points\")\n",
        "\n",
        "# Split data into train and val sets\n",
        "train_data, val_data = train_test_split(data, test_size=0.2)\n",
        "print(f\"\\nSplit data into {len(train_data)} training data points and {len(val_data)} validation data points\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9nhRzefqJQR",
        "outputId": "ced189de-502a-48c2-be23-3c5074a17075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Combined labels and training images into 12272 data points\n",
            "\n",
            "Split data into 9817 training data points and 2455 validation data points\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom Dataset class\n",
        "class PneumoniaDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label_info = self.data[idx]\n",
        "        label = torch.tensor([label_info['class'], label_info['x'], label_info['y'], label_info['width'], label_info['height']], dtype=torch.float32)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "muZOGS1GqMk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Dataset objects for training and validation\n",
        "train_dataset = PneumoniaDataset(train_data)\n",
        "val_dataset = PneumoniaDataset(val_data)\n",
        "\n",
        "# Create DataLoaders for training and validation\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "mpLgreIHqOPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the neural network model class\n",
        "class Net(nn.Module):\n",
        "    # Initialize network layers\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.resnet50 = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)  # Load pre-trained ResNet-50 model\n",
        "        self.resnet50.fc = nn.Linear(self.resnet50.fc.in_features, 120)  # Adjust the last fully connected layer\n",
        "        self.fc2_class = nn.Linear(120, 3)  # 3 outputs for classification\n",
        "        self.fc2_bbox = nn.Linear(120, 4)  # 4 outputs for bounding box\n",
        "\n",
        "    # Define forward pass\n",
        "    def forward(self, x):\n",
        "        x = self.resnet50(x)  # Pass through ResNet-50\n",
        "        x_class = self.fc2_class(x)\n",
        "        x_bbox = self.fc2_bbox(x)\n",
        "        return x_class, x_bbox"
      ],
      "metadata": {
        "id": "M7EqQ3jiqQN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Instantiate the network\n",
        "net = Net()\n",
        "\n",
        "# Use CUDA if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "net.to(device)  # Move model to GPU\n",
        "print(f'The model is using {device}')\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxsNWVjrqTcu",
        "outputId": "894b0bb0-ddcc-4bcd-b46a-c1dd7f164b13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model is using cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "print(\"\\nStarting training ...\")\n",
        "for epoch in range(1):  # loop over the dataset multiple times\n",
        "    print(f\"Starting epoch {epoch}\")\n",
        "    progress_bar = tqdm(enumerate(train_dataloader, 0), total=len(train_dataloader), desc=\"Epoch \" + str(epoch))\n",
        "    for i, data in progress_bar:\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        labels = labels.float()\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        class_outputs, box_outputs = net(inputs) # Unpack the two outputs\n",
        "\n",
        "        class_labels = labels[:, 0].long()\n",
        "        box_labels = labels[:, 1:]\n",
        "\n",
        "        # Get classification loss\n",
        "        class_loss = criterion(class_outputs, class_labels)\n",
        "\n",
        "        # Get localization loss\n",
        "        pos_indices = (class_labels == 2) # Indices where the class is 'Lung Opacity'\n",
        "        localization_loss = F.smooth_l1_loss(box_outputs[pos_indices], box_labels[pos_indices])\n",
        "\n",
        "        # Total loss\n",
        "        loss = class_loss + localization_loss\n",
        "\n",
        "        progress_bar.set_postfix({\"loss\": loss.item()})\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "print('Finished Training\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Q7CRIKxqV-L",
        "outputId": "bd481018-a888-46a5-eddb-5d59357bd731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting training ...\n",
            "Starting epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 0:   0%|          | 0/154 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing actual and predicted class labels\n",
        "true_classes = []\n",
        "pred_classes = []\n",
        "\n",
        "\n",
        "# Validation loop\n",
        "total_iou = 0\n",
        "total_images = 0\n",
        "total_positives = 0\n",
        "\n",
        "for data in val_dataloader:\n",
        "    training_images, labels = data[0].to(device), data[1].to(device)\n",
        "    labels = labels.float()\n",
        "\n",
        "    class_outputs, box_outputs = net(training_images)\n",
        "\n",
        "    class_labels = labels[:, 0].long()\n",
        "    box_labels = labels[:, 1:] # Remaining columns in labels are bounding box coordinates\n",
        "\n",
        "    true_classes.extend(class_labels.cpu().numpy())\n",
        "    pred_classes.extend(torch.argmax(class_outputs, dim=1).cpu().numpy())\n",
        "\n",
        "    # Loop through positive (class 1) predictions only for IOU calculation\n",
        "    for i in range(len(class_labels)):\n",
        "        if class_labels[i] == 2: # Assuming positive class is labeled as 2\n",
        "            true_box = box_labels[i].cpu().numpy()\n",
        "            pred_box = box_outputs[i].cpu().detach().numpy()\n",
        "            total_iou += bb_intersection_over_union(true_box, pred_box)\n",
        "            total_positives += 1\n",
        "\n",
        "    total_images += len(training_images)\n",
        "\n",
        "if total_positives > 0:\n",
        "    # print(\"Average IoU for Positive Cases: \", total_iou / total_positives)\n",
        "    print(f\"Average IoU for Positive Cases: {total_iou} / {total_positives}\")  # Set a static IOU for now\n",
        "else:\n",
        "    print(\"No Positive Cases to Compute IoU\")"
      ],
      "metadata": {
        "id": "Hy5CKGR9qY4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(true_classes, pred_classes)\n",
        "precision = precision_score(true_classes, pred_classes, average='macro')\n",
        "recall = recall_score(true_classes, pred_classes, average='macro')\n",
        "\n",
        "print(\"\\nAccuracy: \", accuracy)\n",
        "print(\"Precision: \", precision)\n",
        "print(\"Recall: \", recall)\n"
      ],
      "metadata": {
        "id": "GdDNJcJOqckv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_outputs = {}\n",
        "with torch.no_grad(): # Disables gradient computation\n",
        "    for image_id, processed_image in test_images.items():\n",
        "        processed_image = processed_image.unsqueeze(0).to(device)\n",
        "        class_output, bbox_output = net(processed_image) # Forward pass through the model\n",
        "        test_outputs[image_id] = {\n",
        "        \"class_output\": class_output.cpu().numpy(),\n",
        "        \"bbox_output\": bbox_output.cpu().numpy()\n",
        "} # Record the output\n"
      ],
      "metadata": {
        "id": "DrWb63CaqfCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting class and bounding box predictions from test outputs\n",
        "test_predictions = {}\n",
        "for image_id, output in test_outputs.items():\n",
        "    class_output = torch.tensor(output[\"class_output\"])\n",
        "    bbox_output = torch.tensor(output[\"bbox_output\"])\n",
        "    class_prediction = torch.argmax(class_output).item()\n",
        "    test_predictions[image_id] = {'class': class_prediction, 'bbox': bbox_output}\n",
        "\n",
        "# Output final results\n",
        "print(\"\\nAverage IoU: \", total_iou / total_images)"
      ],
      "metadata": {
        "id": "38oLnfkdqiNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_predictions(image_path, prediction):\n",
        "    # Read the original image\n",
        "    ds = pydicom.dcmread(image_path)\n",
        "    img = ds.pixel_array\n",
        "\n",
        "    fig, ax = plt.subplots(1)\n",
        "    ax.imshow(img, cmap='gray')\n",
        "\n",
        "    # Get bounding box prediction\n",
        "    bbox = prediction['bbox']\n",
        "    print(bbox)\n",
        "    # Check if the class is 'Lung Opacity' and bounding box dimensions are not zero\n",
        "    if prediction['class'] == 2 and all(b > 0 for b in bbox):  # Assuming class 'Lung Opacity' is mapped to 2\n",
        "        rect = patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], linewidth=2, edgecolor='r', facecolor='none')\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "Hi0USAqLqnhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMwU3r3fpOES"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# Visualize predictions on a few test images\n",
        "for image_id, prediction in list(test_predictions.items())[:5]: # Visualize first 5 predictions\n",
        "    if not image_id.endswith('.dcm'):\n",
        "        image_id += '.dcm'\n",
        "    if prediction['class'] == 2:  # Only visualize if 'Lung Opacity'\n",
        "        image_path = os.path.join(test_img_dir, image_id)\n",
        "        visualize_predictions(image_path, prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WP1xHSsYpTjQ"
      }
    }
  ]
}